# 线性回归问题（Linear Regression）

**回归问题实际是就是找到一个函数$f(x)$通过输入的数据$x$，输出一个值$output$。**
（本节内容来自 NTU ML2017fall）

应用举例：

 - **股市预测**

  $f$(![这里写图片描述](https://img-blog.csdn.net/20180907202848530?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R1a3VrdTUwMzg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70))$= A 股 指数$

 - **自动驾驶**

   $f$(![这里写图片描述](https://img-blog.csdn.net/20180907203011653?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R1a3VrdTUwMzg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)）$= 方向盘的角度$

 - **商品推荐**

$f(用户A，商品B)= 购买的可能性（购买指数）$

回归问题举例：我们要根据已有的口袋妖怪的攻击力Combat Power（CP），估算出他进化后的攻击力（CP）
![这里写图片描述](https://img-blog.csdn.net/20180907210246132?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R1a3VrdTUwMzg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

有了问题，我们就可以使用机器学习的方法来解决：

##机器学习三板斧
###1.设计模型  Model
我们设计线性模型：$\hat{y}=wx_{cp}+b$, x为输入，w为参数，b为偏差（输入数据为10组数据，$x_{cp}$为不同类型的口袋妖怪，预测进化后的$\hat{y}$为攻击值）
![这里写图片描述](https://img-blog.csdn.net/20180907210426729?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R1a3VrdTUwMzg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
有同学可能要问，为什么是线性模型，非线性模型可以吗。 当然可以，线性模型是最简单的回归问题的例子，我们先拿它开刀。
###2. 判断模型好坏 Goodness of function
$Loss = \sum_{i=0}^{10}(\hat{y}-f(x_{cp}))^{2}$
我们找到的函数$f(x)$ 在10个训练数据组中预测的结果和真实结果越相近越好，**（我们关注的的10个训练数据整体Loss最小，并不是一个数据的loss最小，所以使用累加的方法，将是个数据的loss加起来，形成Loss**）也就是说
Loss越小越好，Loss就是我们判断模型好坏的工具

###3. 选择最好的函数 pick the best function
选择最好的函数就是 当Loss最小的时候，参数w 和 偏差 b的值，为了求解这个最小的Loss值的时候的w和b，通常线性代数的方法可以求解。（CS229中有讲解），在这里
我们使用的方法是**梯度下降**（机器学习最通用的方法之一）：Gradient Descent（计划有专门章节讲）。
**根据高中函数极值的概念，极大值、极小值一般在导数为0 的情况：**
![这里写图片描述](https://img-blog.csdn.net/20180907211124239?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R1a3VrdTUwMzg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
我们随机初始化w和b ，寻找导数为0 的情况（图片中的鞍点和局部最小我们暂时忽略）
$\eta$ 为学习率。一般来讲，在导数固定的情况下，学习率越大，w或b变化也就越大。
![这里写图片描述](https://img-blog.csdn.net/20180907211712521?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R1a3VrdTUwMzg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
我们得出的Loss 函数的图形表示为，但是寻找最小值的过程不是一帆风顺的，我们有可能会遇到**学习很慢（导数接近0）、鞍点（导数为0，但是周围还是有下降空间）、局部最小值（导数为0，但是得到的结果不是整体最小值，而是局部最小值）等问题**。但是这些问题都有解决的办法，我们先不考虑。
![这里写图片描述](https://img-blog.csdn.net/2018090721132228?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R1a3VrdTUwMzg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
经过梯度下降，我们选择一个最好的函数（求的的w,b结果为）：
![这里写图片描述](https://img-blog.csdn.net/20180907211518253?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R1a3VrdTUwMzg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
 
我们将这个问题彻底解决了吗，回到开始我们提出的问题，一定要用线性模型吗? 其他模型可否做的更好？ 接下来，我们使用二次模型，看看结果会不会得到提升。
![这里写图片描述](https://img-blog.csdn.net/20180907212110230?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R1a3VrdTUwMzg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
Bingo ! 结果提升了！我们找到的函数是一个平滑的曲线，训练误差几乎少了一半！ 测试误差（在模型没有见过的DATA中）也看起来不错哦。

我们的模型可以更好吗，加上$x_{cp}$的指数项是不是越多越好，指数为三次、四次.. 更多会不会更好.
![这里写图片描述](https://img-blog.csdn.net/20180907212252202?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R1a3VrdTUwMzg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
但是结果和直觉刚好相反，现在我们得出了一个过拟合overfitting的概念，就是在训练数据中（模型见过的数据）表现很好，但是在测试数据中表现很差。那我们如何寻找最好的模型呢，即在训练数据中表现的很好，测试数据中也很稳定。 那么我们就人为的实验，$x_{cp}$的指数的次数1,2,3,4,5。我们发现在指数为3的时候，我们找到的函数是目前最好的。
![这里写图片描述](https://img-blog.csdn.net/20180907212438300?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R1a3VrdTUwMzg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

在这里，我们是不是已经解决了这个预测攻击力的问题了呢。

**还没有！**预测攻击力除了考虑精灵的现在的攻击力外，他的身高，体重等等其他维度的信息都没有考虑，理论上，考虑维度越多，得到的结果越准确。（信息论里有证明）

为了得到更加精确的结果，我们需要

 - 修改模型，增加数据维度
 - 增加正则因子（惩罚因子regularzation）
![这里写图片描述](https://img-blog.csdn.net/20180907213439112?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R1a3VrdTUwMzg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

惩罚因子使得函数更加平滑，让参数w取值更加小，得到的结果更加准确.
那为什么函数w越小，函数就越平滑呢。**因为当x变了一个$x+ \bigtriangleup x$（一个很小的变化量）的时候，整体的$y=w*x+b$ 不会变化太大，所以得到的值也更加准确。**

而且$\lambda $参数的选择，也是经过实验得出, 我们选择测试结果最好的$\lambda $， 在这里，测试结果已经达到Loss=11.1 相对于刚才得出的最好结果（选择指数为3次的函数）18.1，又进步了不少。
![这里写图片描述](https://img-blog.csdn.net/20180907213708887?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R1a3VrdTUwMzg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)


大家现在对线性回归问题有了一个基本的认识了吧，里面涉及到训练数据（Train）、测试数据（Test）的划分，我将进一步和大家一起学习！

